# Lecture Notes

## Introduction to RL

sequential decision making under uncertainty
- optimization
- delayed consequences, but temporal credit assignment is hard
- exploration, but there would be no info about path not taken (censoring)
- generalization

ai planning:
- https://en.wikipedia.org/wiki/Automated_planning_and_scheduling
- e.g. alpha go, doesn't need exploration since the model of the world is given

imitatition learning:
- https://drive.google.com/file/d/12QdNmMll-bGlSWnm8pmD_TawuRN7xagX/view
- assumes input of good policies e.g. Ng's helicopter learning
- reduces RL to supervised learning
- benefits: avoids exploration problem, lots of data, supervised learning has good tools
- limitation: expensive, limited by data collected
- imiation learning + RL can be good

seq learning under uncertainty
- maximizing **expected** future reward






